#langchain
from langchain.chat_models import ChatOpenAI
from langchain.agents.tools import Tool
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from pydantic import BaseModel, Field, validator
from langchain.output_parsers import PydanticOutputParser
from langchain.schema import OutputParserException

#custom
from server_config import openai_api_key
from agents.expert_agent_configs import expert_agent_config_list, expert_agent_prompt_maker
from agents.search_tool_for_agents import get_search_tool_for_agents

#agent insight structure
class AgentInsight(BaseModel):
        """
        Query for an insight generation process
        """
        agent_insight: str = Field(
             description="the short insight generated by the agent", default="null")
        reference_url: str = Field(
             description="the url of the most relevant reference used to generate this insight", default="")
        agent_motive: str = Field(
             description="short motive of why the insight was generated, quoting the text from the transcript", default="")


agent_insight_parser = PydanticOutputParser(pydantic_object=AgentInsight)

#start up the agent blueprint
llm = ChatOpenAI(temperature=0.5, openai_api_key=openai_api_key, model="gpt-4-0613")
agent = initialize_agent([
        get_search_tool_for_agents(),
    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=3, early_stopping_method="generate", verbose=True)

def post_process_agent_output(expert_agent_response, agent_name):
    #agent output should be like
    #{"agent_insight": "null" | "insight", "reference_url": "https://..." | "", "agent_motive": "because ..." | ""}
    
    #add agent name to the json obj
    expert_agent_response["agent_name"] = agent_name

    #clean insight
    agent_insight = expert_agent_response["agent_insight"]
    #handle null insight
    if agent_insight == "null": 
        expert_agent_response = None
    #remove "Insight:" if insight starts with it
    if agent_insight.startswith("Insight:"):
        expert_agent_response["agent_insight"] = agent_insight[len("Insight:"):]

    return expert_agent_response

def run_single_expert_agent(expert_agent_name, convo_context, insights_history: list):
    #initialize the requested expert agent - using the name given
    expert_agent_config = expert_agent_config_list[expert_agent_name]
    #run the agent
    expert_agent_response = expert_agent_run_wrapper(expert_agent_config, convo_context, insights_history)
    #process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_name)

    return expert_agent_response


async def expert_agent_arun_wrapper(expert_agent_config, convo_context, insights_history: list):
    #get agent response
    expert_agent_response = await agent.arun(expert_agent_prompt_maker(expert_agent_config, convo_context, insights_history, format_instructions=agent_insight_parser.get_format_instructions()))
    #post process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_config["agent_name"])

    print("expert_agent_response", expert_agent_response)
    
    return expert_agent_response
    
  

def expert_agent_run_wrapper(expert_agent_config, convo_context, insights_history: list):
    #run the agent
    expert_agent_response = agent.run(expert_agent_prompt_maker(expert_agent_config, convo_context, insights_history, format_instructions=agent_insight_parser.get_format_instructions()))
    #post process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_config["agent_name"])

    print("expert_agent_response", expert_agent_response)

    return expert_agent_response


