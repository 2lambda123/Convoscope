{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Generating Insights using Langchain\n",
    "Here is how you can setup your own insight generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.prompts.chat import SystemMessage\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "search = GoogleSerperAPIWrapper(serper_api_key=\"e1102f25d8a807b8b18e7aa03482122ae4a55c68\")\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=\"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\", model=\"gpt-4-0613\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for our agent\n",
    "We had decided to give our agents the ability to\n",
    "- Search for a query using the web\n",
    "- Scrape a page to find out more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping tool\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "banned_sites = [\"calendar.google.com\", \"researchgate.net\"]\n",
    "\n",
    "def scrape_page(url: str, title: str):\n",
    "    \"\"\"Based on your observations from the Search_Engine, if you want more details from a snippet for a non-PDF page, pass this the page's URL and the page's title to scrape the full page and retrieve the full contents of the page.\"\"\"\n",
    "    \n",
    "    print(\"Parsing: {}\".format(url))\n",
    "    if any(substring in url for substring in banned_sites):\n",
    "        print(\"Skipping site: {}\".format(url))\n",
    "        return None\n",
    "    else: \n",
    "        try:\n",
    "            headers = {\n",
    "              'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "              'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "              'Accept-Encoding': 'none',\n",
    "              'Accept-Language': 'en-US,en;q=0.8',\n",
    "              'Connection': 'keep-alive',\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            text = \" \".join([t.get_text() for t in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])])\n",
    "            return {\n",
    "                'url': url,\n",
    "                'description': text.replace('|',''),\n",
    "                'title': title.replace('|','')\n",
    "            }\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to fetch {url}. Error: {e}\")\n",
    "            return {\n",
    "                'url': url,\n",
    "                'description': None,\n",
    "                'title': title.replace('|','')\n",
    "            }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom search tool, we copied the serper integration on langchain but we prefer all the data to be displayed in one json message\n",
    "\n",
    "from typing import Any, List, Literal\n",
    "import requests\n",
    "\n",
    "k: int = 5\n",
    "gl: str = \"us\"\n",
    "hl: str = \"en\"\n",
    "tbs = None\n",
    "serper_api_key=\"e1102f25d8a807b8b18e7aa03482122ae4a55c68\"\n",
    "search_type: Literal[\"news\", \"search\", \"places\", \"images\"] = \"search\"\n",
    "\n",
    "def serper_search(\n",
    "        search_term: str, search_type: str = \"search\", **kwargs: Any\n",
    "    ) -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"https://google.serper.dev/{search_type}\", headers=headers, params=params\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    return search_results\n",
    "\n",
    "def parse_snippets(results: dict) -> List[str]:\n",
    "    result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "    snippets = []\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        if answer_box.get(\"answer\"):\n",
    "            snippets.append(answer_box.get(\"answer\"))\n",
    "        elif answer_box.get(\"snippet\"):\n",
    "            snippets.append(answer_box.get(\"snippet\").replace(\"\\n\", \" \"))\n",
    "        elif answer_box.get(\"snippetHighlighted\"):\n",
    "            snippets.append(answer_box.get(\"snippetHighlighted\"))\n",
    "\n",
    "    if results.get(\"knowledgeGraph\"):\n",
    "        kg = results.get(\"knowledgeGraph\", {})\n",
    "        title = kg.get(\"title\")\n",
    "        entity_type = kg.get(\"type\")\n",
    "        if entity_type:\n",
    "            snippets.append(f\"{title}: {entity_type}.\")\n",
    "        description = kg.get(\"description\")\n",
    "        if description:\n",
    "            snippets.append(description)\n",
    "        for attribute, value in kg.get(\"attributes\", {}).items():\n",
    "            snippets.append(f\"{title} {attribute}: {value}.\")\n",
    "\n",
    "    for result in results[result_key_for_type[search_type]][:k]:\n",
    "        if \"snippet\" in result:\n",
    "            snippets.append(str(result))\n",
    "            # snippets.append(scrape_page(result[\"link\"], result[\"title\"]))\n",
    "        # for attribute, value in result.get(\"attributes\", {}).items():\n",
    "        #     snippets.append(f\"{attribute}: {value}.\")\n",
    "\n",
    "        # print(result)\n",
    "\n",
    "    if len(snippets) == 0:\n",
    "        return [\"No good Google Search Result was found\"]\n",
    "    return snippets\n",
    "\n",
    "def parse_results(results: dict) -> str:\n",
    "        snippets = parse_snippets(results)\n",
    "        results_string = \"\"\n",
    "        for idx, val in enumerate(snippets):\n",
    "            results_string += f\"Result {idx}: \" + val + \"\\n\"\n",
    "        return results_string\n",
    "\n",
    "def custom_search(query: str, **kwargs: Any):\n",
    "\n",
    "    results = serper_search(\n",
    "            search_term=query,\n",
    "            gl=gl,\n",
    "            hl=hl,\n",
    "            num=k,\n",
    "            tbs=tbs,\n",
    "            search_type=search_type,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    return parse_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing episode_103_large...\n",
      "Processing episode_009_large...\n",
      "Processing episode_190_large...\n",
      "Processing episode_064_large...\n",
      "Processing episode_191_large...\n",
      "Processing episode_260_large...\n",
      "Processing episode_235_large...\n",
      "Processing episode_258_large...\n",
      "Processing episode_181_large...\n",
      "Processing episode_297_large...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" that's growing faster than you can utilize. Now I'm ahead, absolutely. But there's some sorting procedure depending on mood and interest and so on. But okay, so you pick an idea and then you have to try to write a narrative arc that sort of, how do I elucidate? How do I make this idea beautiful and clear, and explain it? And then there's a set of visualizations that will be attached to it. Sort of, you've talked about some of this before, but sort of writing the story, attaching the visualizations. Can you talk through interesting, painful, beautiful parts of that process? Well, the most painful is if you've chosen a topic that you do want to do, but then it's hard to think of,, I guess how to structure the script. This is sort of where I have been on one for like the last two or three months. And I think that ultimately the right resolution is just like set it aside and instead do some other things where the script comes more naturally. Because you sort of don't want to overwork a narrative. The more you've thought about it, the less you can empathize with the student who doesn't yet understand the thing you're trying to teach., Who is the judger in your head? Sort of the person, the creature, the essence that's saying this sucks or this is good. And you mentioned kind of the student you're thinking about. Can you, who is that? What is that thing? That says, the perfectionist that says this thing sucks., You need to work on that for another two, three months. I don't know. I think it's my past self. I think that's the entity that I'm most trying to empathize with is like you take who I was, because that's kind of the only person I know. Like you don't really know anyone other than versions of yourself. So I start with the version of myself that I know who doesn't yet understand the thing, right? And then I just try to view it with fresh eyes,\\n a particular visual or a particular script. Like, is this motivating? Does this make sense? Which has its downsides, because sometimes I find myself speaking to motivations that only myself would be interested in. I don't know, like I did this project on quaternions where what I really wanted was to understand what are they doing in four dimensions? Can we see what they're doing in four dimensions, right?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way to generate a random test input using transcripts from Lex Fridman's podcast\n",
    "# Make sure you have the transcripts downloaded in the folder lex_whisper_transcripts\n",
    "\n",
    "import test_on_lex\n",
    "\n",
    "transcripts = test_on_lex.load_lex_transcripts(random_n=10, transcript_folder=\"./lex_whisper_transcripts/\", chunk_time_seconds=20)\n",
    "\n",
    "import random\n",
    "def generate_test_input():\n",
    "    idx = random.randint(0, 10)\n",
    "    key = list(transcripts.keys())[idx]\n",
    "    transcript = transcripts[key]\n",
    "    trans_idx = random.randint(10, len(transcript)-10)\n",
    "    latest = transcript[trans_idx:trans_idx+7]\n",
    "    prev_transcripts, curr_transcripts = str.join(\",\", list(latest[0:5])), latest[5]\n",
    "    # return f\"\"\"<Old Transcripts>\n",
    "    # {prev_transcripts}\n",
    "    # <New Transcripts>\n",
    "    # {curr_transcripts}\"\"\"\n",
    "    return prev_transcripts + \"\\n\" + curr_transcripts\n",
    "\n",
    "generate_test_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent prompt here\n",
    "\n",
    "generate_prompt = lambda x: f\"\"\"\n",
    "I need some help with a task, you need to imagine the following scenario. I will first provide you some custom definitions to follow, your objective in this task, how the input is structured, and the final task.\n",
    "\n",
    "<Scenario start>\n",
    "[Definitions]\n",
    "- \"Insights\": Intelligent analysis, ideas, arguments, questions to ask, and deeper insights that will help the user improve the flow within their conversations. \n",
    "- \"Convoscope\": a tool that listens to a user's live conversation and enhances their conversation flow by providing them with real time \"Insights\", which will often lead the user to deeper understanding, broader perspective, new ideas, and better replies. Convoscope has 2 independent components\n",
    "1) a planner which will outline detailed steps for the insight generation process\n",
    "2) an executor which will execute the steps\n",
    "\n",
    "[Your Objective]\n",
    "You are the \"Insight\" generator of \"Convoscope\". Your primary function is to outline a plan to generate an \"Insight\" for the user, based on live transcription streams of their ongoing conversation, and search for additional information to ensure that the \"Insight\" you generated is factual.\n",
    "\n",
    "[User Live Transcript Structure]\n",
    "You will receive inputs below which represent the current live conversation the user is having.\n",
    "<Old Transcripts>\n",
    "{{Previous transcripts from the conversation, which you should read to understand the short/mid term context of the conversation, to help figure out what information to provide the user.}}\n",
    "<New Transcripts>\n",
    "{{latest transcripts from the conversation, we should generate definitions and insights that will help the user based on the New Transcript.}}\n",
    "\n",
    "[Example \"Insights\"]\n",
    "The following are some examples of \"Insights\" that \"Convoscope\" generated for a given conversation. We prefer insights that highlights quantitative insights where possible.\n",
    "\n",
    "User Conversation: At an expo, a competitor unveils a tech gadget boasting a new \"nano-silicon\" battery. A battery icon with an 'N' in its center appears on your glasses, with a subscript: \"Nano-Silicon: +300% Capacity.\" Equipped with this insight, you gauge the competition's edge more accurately.\n",
    "\"Insight\": \"Nano-Silicon: +300% battery capacity\"\n",
    "\n",
    "User Conversation: A friend claims that the Keto diet is the most effective for rapid weight loss. As the debate heats up, your glasses flash a comparison chart of popular diets over a three-month period. While Keto shows initial rapid loss, another diet displays more sustainable results. You share this, shifting the conversation from short-term efficacy to long-term health benefits.\n",
    "\"Insight\": \"Keto: Rapid but short-term loss\"\n",
    "\n",
    "User Conversation: As the table discusses the viability of Mars colonization, someone skeptically mentions the resource cost. Your glasses project a concise infographic comparing the cost of space missions against their potential for resource discovery, like water or minerals on Mars. This propels the conversation from expenditure critique to the potential returns of such endeavors.\n",
    "\"Insight\": \"Mars: Potential water, mineral discovery\"\n",
    "\n",
    "User Conversation: A neighbor mentions buying only from brands that use recycled materials. Your glasses showcase a quick pie chart on a brand she mentions, depicting its material sources. While a chunk is recycled, a notable portion isn't. You gently introduce the topic of greenwashing in the industry, leading to a broader discussion on informed consumer choices.\n",
    "\"Insight\": \"Brand: Only 40% truly recycled\"\n",
    "\n",
    "User Conversation: In a workshop focused on wearable technology, a debate arises about the balance between functionality and cognitive load. Your glasses quickly reference several cognitive load theories and provide a visual overlay of optimal data chunks for quick consumption. This aids the team in determining just how much information a wearable should display at any given moment to be both useful and user-friendly.\n",
    "\"Insight\": \"Optimal: 3-7 word data chunks\"\n",
    "\n",
    "User Conversation: While discussing the cultural adaptation of voice assistants, a colleague wonders how regional accents influence user satisfaction. Your glasses aggregate global user reviews and present a correlation graph: regions with stronger accents tend to report lower satisfaction. This sparks a deeper dive into developing accent-inclusive training data for voice recognition.\n",
    "\"Insight\": \"Stronger accents: Lower voice-assist satisfaction\"\n",
    "\n",
    "<Task start>\n",
    "I need you to help me generate a similar \"Insight\" based on the examples on top for the following conversation transcript. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts.\n",
    "\n",
    "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include\n",
    "1. Identify the best \"Insight\" you could generate to enhance the user's conversation, preferably an \"Insight\" with quantitative data. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. Come up with a general description of the \"Insight\" to generate.\n",
    "2. What information you need to generate the \"Insight\" (preferably quantitative data) and where to find the information\n",
    "3. A final step to generate the insight. The insight should be summarized within 12 words and be in the format `Insight: {{Insert your \"Insight\" here}}`\n",
    "<Task end>\n",
    "\n",
    "<Transcript start>{x}<Transcript end>\n",
    "<Scenario end>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the agent together here\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agent_executor = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "        ),\n",
    "        StructuredTool.from_function(scrape_page)\n",
    "    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the agent together here\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agent_executor = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "        ),\n",
    "        # StructuredTool.from_function(scrape_page)\n",
    "    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Old Transcripts>\n",
      "     It's a bit of a trap, but I certainly find it very difficult to feel happy when I'm not being productive. It's become slightly better. If I know my students are being productive, I can be happy. But I think a lot of senior scientists, once they get into that mindset, they start thinking that their student science is theirs. And I think this happens a lot with senior scientists., They have so many hats, as you mentioned, they have to do so much service and so much admin, that they have very little time for their own science. And so they end up feeling ownership over the junior people in their labs and their groups. And that's really heartbreaking. I see it all the time. And that, I think I've escaped that trap., I feel so happy, even when I'm not productive, when my students are productive. I think that sensation I was describing earlier of they only need to be half as productive as me for me to feel like I've done my job for humanity. So that has been the dynamic I've had to worry about., But to be productive is not clear to me what you have to do. You have to not be miserable otherwise. I find it extremely hard when I'm having conflicts with collaborators, for example, kind of very hard to enjoy the work we do. Even if the work is this fantastical phosphine or things that I know I love, still very difficult. So I think choosing your collaborators based on how well you get along with them is a really, sound scientific choice. Being a miserable collaborator ruins your whole life. It's horrible. It makes you not want to do the science. It probably makes you do clumsy science because you don't focus on it. You don't go over it several times. You just want it to be over. And so I think in general, just not being a douchebag can get so much good science done.\n",
      "    <New Transcripts>\n",
      "     Just find the good people in your community and collaborate with them. Even if they're not as good scientists as others, you'll get better science out. Yeah, don't be a douchebag yourself and surround yourself by other cool people. Exactly. And then you'll get better science than if you would try to work with three geniuses who are just hell to be around. Yeah. I mean, there's parallel things like that.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The conversation revolves around the topic of productivity in scientific research and the impact of collaboration on it. The user is discussing the importance of choosing collaborators based on how well they get along, rather than just their scientific prowess. The user suggests that working with good people, even if they're not the best scientists, can lead to better science. An interesting insight could be to provide quantitative data on the impact of positive collaboration on productivity in scientific research. \n",
      "\n",
      "Plan:\n",
      "1. The \"Insight\" to generate could be about the correlation between positive collaboration and productivity in scientific research. This would provide additional understanding to the conversation by backing up the user's point with quantitative data.\n",
      "2. To generate this \"Insight\", I would need data on the impact of positive collaboration on productivity in scientific research. This could include studies or research papers that have investigated this correlation. The Search Engine tool can be used to find this information.\n",
      "3. The final step would be to summarize the found data into a concise \"Insight\" that fits within the 12-word limit. The format would be \"Insight: {Insert your \"Insight\" here}\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"impact of positive collaboration on productivity in scientific research\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'The Impact of Research Collaboration on Scientific Productivity - JSTOR', 'link': 'https://www.jstor.org/stable/25046667', 'snippet': 'apparently most scientists that scientific collaboration has positive effects on scientific productivity. The collaboration-as-synergy assumption affects.', 'position': 1}\n",
      "Result 1: {'title': 'The Impact of Research Collaboration on Scientific Productivity - Sooho Lee, Barry Bozeman, 2005 - Sage Journals', 'link': 'https://journals.sagepub.com/doi/10.1177/0306312705052359', 'snippet': 'Since characteristics of the individual and the work environment are endogenously related to both collaboration and productivity, this study focuses on the ...', 'position': 2}\n",
      "Result 2: {'title': 'The Impact of Research Collaboration on Scientific Productivity - Sage Journals', 'link': 'https://journals.sagepub.com/doi/pdf/10.1177/0306312705052359', 'snippet': 'Surprisingly few studies have actually tested that proposition. Certainly, there are good reasons to think that collaboration may enhance research productivity.', 'position': 3}\n",
      "Result 3: {'title': '[PDF] The relationship among research productivity, research collaboration, and their determinants1 Giovanni Abramo Laboratory for Stu - arXiv', 'link': 'https://arxiv.org/pdf/1810.12634', 'snippet': 'H1: The propensity to collaborate generally has a positive impact on research productivity. This positive effect is higher for international collaborations than ...', 'position': 4}\n",
      "Result 4: {'title': 'Impactful scientists have higher tendency to involve collaborators in new topics - PNAS', 'link': 'https://www.pnas.org/doi/10.1073/pnas.2207436119', 'snippet': 'We find that, compared to productive scientists, impactful scientists show strong preference of collaboration with high-impact scientists on a ...', 'date': 'Aug 8, 2022', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results confirm that there is a positive correlation between collaboration and productivity in scientific research. One of the results even suggests that the positive effect is higher for international collaborations. This information can be used to generate an \"Insight\" that supports the user's point in the conversation. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Insight: Positive collaboration boosts research productivity\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Insight: Positive collaboration boosts research productivity'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "agent_executor.run(generate_prompt(test_transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_master_prompt = lambda x: f\"\"\"\n",
    "You are the master agent of \"Convoscope\". \"Convoscope\" is a tool that listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\". The \"Insights\" you generate should aim to lead the user to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. \n",
    "\n",
    "[Your Objective]\n",
    "\"Convoscope\" is a multi-agent system in which you are the master agent. You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your knowledge and tools to generate \"Insights\" for the user.\n",
    "\n",
    "<Task start>\n",
    "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool or agent fails to fulfill your request, don't run the same request on the same agent again. \n",
    "\n",
    "In your initial thought, you should first write down a plan to generate the \"Insight\". The plan should include\n",
    "1. Read the incoming conversation transcript and identify the best \"Insight\" you could generate to enhance the user's conversation.  Come up with a general description of the \"Insight\" to generate.\n",
    "2. What tool(s), agent(s), information you need to generate the \"Insight\".\n",
    "3. A final step to almagamate your and your worker agent's work to generate the \"Insight\". The insight should be summarized within 12 words and be in the format `Insight: {{Insert your \"Insight\" here}}`\n",
    "<Task end>\n",
    "\n",
    "<Transcript start>{x}<Transcript end>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_to_user = lambda x: print(\">>>>>>>>>>PRINT TO USER: >>>>>>>>>>>>>>\\n\" + x + \"\\n>>>>>>>>>>END PRINT TO USER: >>>>>>>>>>>>>>\\n\")\n",
    "\n",
    "# definer_agent = initialize_agent([\n",
    "#         Tool(\n",
    "#             name=\"Search_Engine\",\n",
    "#             func=custom_search,\n",
    "#             description=\"Use this tool to search for definitions of an unknown word or slang or jargon\",\n",
    "#         ),\n",
    "#         Tool(\n",
    "#             name=\"Output_To_User\",\n",
    "#             func=output_to_user,\n",
    "#             description=\"Use this tool to output the results to the user when you have definitions of a rare word or slang or jargon\",\n",
    "#         )\n",
    "#     ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agents = [[]]\n",
    "\n",
    "statistician_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for statistics and facts about a topic. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def statistician_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"You are a statistician agent.\\n\"\"\"\n",
    "    return statistician_agent.run(system_prompt + command)\n",
    "\n",
    "devils_advocate_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for facts that might contradict the user's current conversation. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def devils_advocate_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"\\n\"\"\"\n",
    "    return devils_advocate_agent.run(system_prompt + command)\n",
    "\n",
    "fact_checker_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for statistics and facts about a topic. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def fact_checker_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"You are a fact checker agent.\\n\"\"\"\n",
    "    return fact_checker_agent.run(system_prompt + command)\n",
    "    \n",
    "master_agent = initialize_agent([\n",
    "        # Tool(\n",
    "        #     name=\"Definer_Agent\",\n",
    "        #     func=definer_agent.run,\n",
    "        #     description=\"Use this tool to search for definitions of an unknown word or slang or jargon\",\n",
    "        # ),\n",
    "        Tool(\n",
    "            name=\"Statistician_Agent\",\n",
    "            func=statistician_agent_wrapper,\n",
    "            description=\"\"\"When to call this agent: Occurrences in a conversation where statistics and graphs would be useful to the user.\"\"\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Devils_Advocate_Agent\",\n",
    "            func=devils_advocate_agent_wrapper,\n",
    "            description=\"\"\"When to call this agent: When it would be useful for the user to see a devil’s advocate opinion (a steel-man argument supporting a viewpoint different from their own).\"\"\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Fact_Checker_Agent\",\n",
    "            func=fact_checker_agent_wrapper,\n",
    "            description=\"\"\"When to call this agent: If a statement is made which you suspect might be false, and that statement is falsifiable with free and public knowledge. Don't use this to verify your own search and ideas, only use this to verify the user's statements.\"\"\",\n",
    "        )\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" on the surface of the mug, right? That's definitely something I could do. I could shrink it, shrink it, shrink it until it's a point. On the other hand, if I draw a loop that goes around the handle, I can kind of zhuzh it up here and I can zhuzh it down there and I can sort of slide it up and down the handle, but I can't pull it closed, can I? It's trapped. Not without breaking the surface of the mug, right? Not without like going inside. So the condition of being what's called simply connected,, this is one of Poincare's inventions, says that any loop of string can be pulled shut. So it's a feature that the mug simply does not have. This is a non simply connected mug and a simply connected mug would be a cup, right? You would burn your hand when you drank coffee out of it. So you're saying the universe is not a mug. Well, I can't speak to the universe,, but what I can say is that regular old space is not a mug. Regular old space, if you like sort of actually physically have like a loop of string, you can pull it shut. You can always pull it shut. But what if your piece of string was the size of the universe? Like what if your piece of string was like billions of light years long? Like how do you actually know? I mean, that's still an open question, of the shape of the universe. Exactly. I think there's a lot, there is ideas of it being a torus. I mean, there's some trippy ideas and they're not like weird out there controversial. There's legitimate at the center of a cosmology debate. I mean, I think most people think it's flat. I think there's some kind of dodecahedral symmetry or I mean, I remember reading something crazy, about somebody saying that they saw the signature of that in the cosmic noise or what have you. I mean. To make the flat earthers happy, I do believe that the current main belief is it's flat. It's flat ish or something like that. The shape of the universe is flat ish. I don't know what the heck that means. I think that has like a very,\\n how are you even supposed to think about the shape of a thing that doesn't have any thing outside of it? I mean. Ah, but that's exactly what topology does. Topology is what's called an intrinsic theory. That's what's so great about it. This question about the mug, you could answer it without ever leaving the mug, right? Because it's a question about a loop drawn\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "test_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The conversation revolves around the concept of topology, specifically the idea of \"simply connected\" objects and the shape of the universe. The user seems to be interested in the idea of the universe's shape and how it relates to the concept of being \"simply connected\". An insightful addition to this conversation could be a comparison of the universe's shape to known topological shapes, or a brief explanation of the current theories about the universe's shape. To generate this insight, I would need to gather information about the current theories regarding the shape of the universe, and possibly some basic information about topology and \"simply connected\" shapes. This information could be found in scientific literature or reliable online sources. The final insight could be something like \"Universe: Possibly flat, torus, or dodecahedral symmetry\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Statistician_Agent\",\n",
      "  \"action_input\": \"current theories about the shape of the universe\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find information about the current theories regarding the shape of the universe. I will use the Search Engine tool to find this information.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"current theories about the shape of the universe\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': \"What Shape Is the Universe? A New Study Suggests We've Got It All Wrong\", 'link': 'https://www.quantamagazine.org/what-shape-is-the-universe-closed-or-flat-20191104/', 'snippet': 'A provocative paper published today in the journal Nature Astronomy argues that the universe may curve around and close in on itself like a ...', 'date': 'Nov 4, 2019', 'position': 1}\n",
      "Result 1: {'title': 'What shape is the universe? - Astronomy Magazine', 'link': 'https://www.astronomy.com/science/what-shape-is-the-universe/', 'snippet': 'The theory of general relativity, under which space itself can curve, allows for the universe to take one of three forms: flat like a sheet ...', 'date': 'Feb 23, 2021', 'position': 2}\n",
      "Result 2: {'title': 'Shape of the universe - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Shape_of_the_universe', 'snippet': 'The shape of the universe, in physical cosmology, is the local and global geometry of the universe. The local features of the geometry of the universe are ...', 'sitelinks': [{'title': '3-torus', 'link': 'https://en.wikipedia.org/wiki/3-torus'}, {'title': 'Homology sphere', 'link': 'https://en.wikipedia.org/wiki/Homology_sphere'}, {'title': 'Zero-energy', 'link': 'https://en.wikipedia.org/wiki/Zero-energy_universe'}], 'position': 3}\n",
      "Result 3: {'title': 'Is the universe really flat? New theory suggests otherwise - Science News - WION', 'link': 'https://www.wionews.com/science/what-is-the-shape-of-our-universe-new-theory-suggests-it-might-not-be-flat-after-all-576053', 'snippet': 'Now a new study on the shape of the universe has come up with an intriguing theory that changes our perception of the universe. The latest ...', 'date': 'Mar 27, 2023', 'position': 4}\n",
      "Result 4: {'title': 'How do we know the shape of the Universe? - BBC Science Focus Magazine', 'link': 'https://www.sciencefocus.com/space/what-shape-is-the-universe', 'snippet': \"According to Einstein's theory of General Relativity, the Universe could take one of three forms: flat like a piece of paper, closed like a ...\", 'date': 'Apr 26, 2022', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that there are several theories about the shape of the universe. Some suggest that the universe may curve around and close in on itself, while others propose that it could be flat. The theory of general relativity also allows for the universe to take one of three forms: flat, closed, or something else. To get a more detailed understanding, I should look at a more comprehensive source, such as the Wikipedia page on the shape of the universe. I will use the Search Engine tool to find this information.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Shape of the universe Wikipedia\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Shape of the universe - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Shape_of_the_universe', 'snippet': 'The shape of the universe, in physical cosmology, is the local and global geometry of the universe. The local features of the geometry of the universe are ...', 'sitelinks': [{'title': '3-torus', 'link': 'https://en.wikipedia.org/wiki/3-torus'}, {'title': 'Homology sphere', 'link': 'https://en.wikipedia.org/wiki/Homology_sphere'}, {'title': 'Zero-energy', 'link': 'https://en.wikipedia.org/wiki/Zero-energy_universe'}], 'position': 1}\n",
      "Result 1: {'title': 'Universe - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Universe', 'snippet': 'The universe is all of space and time and their contents, including planets, stars, galaxies, and all other forms of matter and energy.', 'sitelinks': [{'title': 'Definition', 'link': 'https://en.wikipedia.org/wiki/Universe#Definition'}, {'title': 'Etymology', 'link': 'https://en.wikipedia.org/wiki/Universe#Etymology'}, {'title': 'Physical properties', 'link': 'https://en.wikipedia.org/wiki/Universe#Physical_properties'}, {'title': 'Composition', 'link': 'https://en.wikipedia.org/wiki/Universe#Composition'}], 'position': 2}\n",
      "Result 2: {'title': 'Shape of the universe - Simple English Wikipedia, the free encyclopedia', 'link': 'https://simple.m.wikipedia.org/wiki/Shape_of_the_universe', 'snippet': 'The observable universe is the basis for testing any model of the universe. It is a spherical volume (a ball) centered on the observer, regardless of the shape ...', 'position': 3}\n",
      "Result 3: {'title': 'Observable universe - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Observable_universe', 'snippet': 'The observable universe is a ball-shaped region of the universe comprising all matter that can be observed from Earth or its space-based telescopes and ...', 'position': 4}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provide a link to the Wikipedia page on the shape of the universe. This page should contain comprehensive information about the current theories regarding the shape of the universe. I will use this information to answer the question. \n",
      "\n",
      "Final Answer: The shape of the universe, according to current theories, could take several forms. Some theories suggest that the universe may curve around and close in on itself, creating a closed universe. Other theories propose that the universe could be flat, similar to a sheet of paper. These theories are based on the principles of general relativity, which allows for the universe to take one of three forms: flat, closed, or something else. However, these theories are still under debate and research is ongoing to determine the true shape of the universe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe shape of the universe, according to current theories, could take several forms. Some theories suggest that the universe may curve around and close in on itself, creating a closed universe. Other theories propose that the universe could be flat, similar to a sheet of paper. These theories are based on the principles of general relativity, which allows for the universe to take one of three forms: flat, closed, or something else. However, these theories are still under debate and research is ongoing to determine the true shape of the universe.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered, it seems that the shape of the universe is still a topic of ongoing research and debate. The theories suggest that the universe could be flat, closed, or something else entirely. This information could provide an interesting insight to the user's conversation about the shape of the universe and its relation to topology. \n",
      "\n",
      "Final Answer: \"Insight: Universe's shape: Flat, closed, or other - still under debate\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Insight: Universe\\'s shape: Flat, closed, or other - still under debate\"'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_agent.run(generate_prompt(test_transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" and hope the machine will learn to do a better job at predicting next time around. There's a huge amount of information you give the machine because it's an entire video clip of the future after the video clip you fed it in the first place. So both for language and for vision, there's a subtle, seemingly trivial construction,, but maybe that's representative of what is required to create intelligence, which is filling the gap. So it sounds dumb, but can you, it is possible you could solve all of intelligence in this way, just for both language, just give a sentence and continue it, or give a sentence and there's a gap in it, some words blanked out and you fill in what words go there. For vision, you give a sequence of images and predict what's going to happen next, or you fill in what happened in between. Do you think it's possible that formulation alone as a signal for self supervised learning, can solve intelligence for vision and language? I think that's the best shot at the moment. So whether this will take us all the way to human level intelligence or something, or just cat level intelligence is not clear, but among all the possible approaches that people have proposed, I think it's our best shot. So I think this idea of an intelligent system, filling in the blanks, either predicting the future, inferring the past, filling in missing information, I'm currently filling the blank of what is behind your head and what your head looks like from the back, because I have basic knowledge about how humans are made. And I don't know what you're going to say,\\n at which point you're going to speak, whether you're going to move your head this way or that way, which way you're going to look, but I know you're not going to just dematerialize and reappear three meters down the hall, because I know what's possible and what's impossible according to intuitive physics. You have a model of what's possible and what's impossible and then you'd be very surprised if it happens and then you'll have to reconstruct your model.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "test_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The conversation revolves around the concept of machine learning, specifically self-supervised learning, and its potential to reach human or even cat level intelligence. The speakers discuss the idea of an intelligent system filling in the blanks, predicting the future, inferring the past, and filling in missing information. A potential \"Insight\" could be the current state of self-supervised learning in AI research, specifically how far we are from achieving human or cat level intelligence. To generate this \"Insight\", I would need to find recent research or statistics on the progress of self-supervised learning in AI. The final \"Insight\" could be a brief summary of this information, such as \"Self-supervised learning: X% towards human intelligence\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Statistician_Agent\",\n",
      "  \"action_input\": \"What is the current progress of self-supervised learning in AI towards achieving human or cat level intelligence?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find the latest research and advancements in self-supervised learning in AI. I will use the Search Engine tool to find this information.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"latest advancements in self-supervised learning in AI\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Self-supervised learning trends and what to expect in 2023 - Lightly', 'link': 'https://www.lightly.ai/post/self-supervised-learning-trends-and-what-to-expect-in-2023', 'snippet': 'Recent trends in self-supervised learning · Masked image modeling · Multi-modal models · The advent of contrastive loss in CLIP · Self-supervised pre-training on ...', 'position': 1}\n",
      "Result 1: {'title': 'Self-Supervised Learning and Its Applications - neptune.ai', 'link': 'https://neptune.ai/blog/self-supervised-learning', 'snippet': 'Explore self-supervised learning: its algorithms, differences from unsupervised learning, applications, and challenges.', 'position': 2}\n",
      "Result 2: {'title': 'Recent Advances in Self-Supervised and Unsupervised Representation Learning (2019~2022). | by Ching (Chingis) | Analytics Vidhya | Medium', 'link': 'https://medium.com/analytics-vidhya/recent-advances-in-self-supervised-and-unsupervised-representation-learning-2019-2022-1553a45cf8fd', 'snippet': 'MoCo v3. It was developed for self-supervised ResNet and ViT and proposed last year by Kaiming He et al. I would like to summarize the ...', 'date': 'Feb 11, 2022', 'position': 3}\n",
      "Result 3: {'title': 'SEER: A Breakthrough in Self-Supervised Computer Vision Models? - Unite.AI', 'link': 'https://www.unite.ai/seer-a-breakthrough-in-self-supervised-computer-vision-models/', 'snippet': \"This approach is known as self-supervised learning, and it's one of the most efficient methods to build ML and AI models that have the “common ...\", 'date': 'Jul 31, 2023', 'position': 4}\n",
      "Result 4: {'title': '[2111.02042] Recent Advancements in Self-Supervised Paradigms for Visual Feature Representation - arXiv', 'link': 'https://arxiv.org/abs/2111.02042', 'snippet': 'This study conducts a comprehensive and insightful survey and analysis of recent developments in the self-supervised paradigm for feature ...', 'date': 'Nov 3, 2021', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provide some insights into the recent advancements in self-supervised learning in AI. However, they do not directly address the progress towards achieving human or cat level intelligence. I need to refine my search to find more specific information about the progress of self-supervised learning in achieving such levels of intelligence.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"self-supervised learning progress towards human or cat level intelligence\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Yann LeCun and Yoshua Bengio: Self-supervised learning is the key to human-level intelligence | VentureBeat', 'link': 'https://venturebeat.com/ai/yann-lecun-and-yoshua-bengio-self-supervised-learning-is-the-key-to-human-level-intelligence/', 'snippet': \"Self-supervised learning could lead to the creation of AI that's more humanlike in its reasoning, according to Turing Award winners Yoshua ...\", 'date': 'May 2, 2020', 'position': 1}\n",
      "Result 1: {'title': 'Self-supervised learning: The dark matter of intelligence - Meta AI', 'link': 'https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/', 'snippet': 'Self-supervision is one step on the path to human-level intelligence, but there are surely many steps that lie behind this one.', 'date': 'Mar 4, 2021', 'position': 2}\n",
      "Result 2: {'title': 'Self-Taught AI Shows Similarities to How the Brain Works | Quanta Magazine', 'link': 'https://www.quantamagazine.org/self-taught-ai-shows-similarities-to-how-the-brain-works-20220811/', 'snippet': 'These self-supervised learning approaches “are progress in the sense that you are able to learn representations that can support a lot of ...', 'date': 'Aug 11, 2022', 'position': 3}\n",
      "Result 3: {'title': 'Will Machine Intelligence\\ufeff Surpass Human Intelligence? - Yann LeCun - YouTube', 'link': 'https://youtube.com/watch?v=AgLW288bO1Q', 'snippet': 'Abstract How could machines learn as efficiently as ...', 'date': 'Mar 2, 2023', 'attributes': {'Duration': '1:03:05', 'Posted': 'Mar 2, 2023'}, 'imageUrl': 'https://i.ytimg.com/vi/AgLW288bO1Q/default.jpg?sqp=-oaymwEECHgQQw&rs=AMzJL3miLwl0vSMVdPtuMPqXfmx1vB5_Gw', 'position': 4}\n",
      "Result 4: {'title': 'Yann LeCun @EPFL - \"Self-supervised learning: could machines learn like humans?\"', 'link': 'https://youtube.com/watch?v=7I0Qt7GALVk', 'snippet': 'Conference by Yann LeCun, computer scientist working in ...', 'date': 'Oct 5, 2018', 'attributes': {'Duration': '1:19:33', 'Posted': 'Oct 5, 2018'}, 'imageUrl': 'https://i.ytimg.com/vi/7I0Qt7GALVk/default.jpg?sqp=-oaymwEECHgQQw&rs=AMzJL3kIZSLOG2mazRTo_LGlOUhmjGYopg', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that self-supervised learning is considered a significant step towards achieving human-level intelligence in AI. However, it is also noted that there are many steps that lie behind this one, suggesting that while progress has been made, there is still a long way to go. There is no specific mention of achieving cat level intelligence. To provide a more comprehensive answer, I should look for more information on the challenges and limitations of self-supervised learning in AI.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"challenges and limitations of self-supervised learning in AI\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'You Need to Know the Pros and Cons of Self-Supervised Learning', 'link': 'https://itchronicles.com/artificial-intelligence/you-need-to-know-the-pros-and-cons-of-self-supervised-learning/', 'snippet': 'One of the most significant limitations to self-supervised learning is its computing demands. As you might expect, automatically scanning and ...', 'date': 'Nov 21, 2022', 'position': 1}\n",
      "Result 1: {'title': 'Self-Supervised Learning: Challenges and Next Steps? | by Jayant Kumar - Medium', 'link': 'https://medium.com/swlh/self-supervised-learning-challenges-and-next-steps-d324d265a31c', 'snippet': 'One of the main ideas is to force the network to learn useful features by doing predictions on some pre-text tasks. A robot exploring its environment and ...', 'position': 2}\n",
      "Result 2: {'title': 'Self-Supervised Learning: Everything you need to know (2023) - viso.ai', 'link': 'https://viso.ai/deep-learning/self-supervised-learning-for-computer-vision/', 'snippet': 'Disadvantages and Advantages of Self Supervised Learning ; Enables learning from unlabeled data, which is more abundant and easier to acquire in some cases ...', 'sitelinks': [{'title': 'Disadvantages and...', 'link': 'https://viso.ai/deep-learning/self-supervised-learning-for-computer-vision/#elementor-toc__heading-anchor-5'}, {'title': 'Self Supervised Learning...', 'link': 'https://viso.ai/deep-learning/self-supervised-learning-for-computer-vision/#elementor-toc__heading-anchor-7'}], 'position': 3}\n",
      "Result 3: {'title': 'What are the disadvantages of self-supervised learning in ML? [closed] - Stack Overflow', 'link': 'https://stackoverflow.com/questions/69097885/what-are-the-disadvantages-of-self-supervised-learning-in-ml', 'snippet': \"My opinion here is that this system isn't better intrinsically than a human-based one.\", 'date': 'Sep 8, 2021', 'position': 4}\n",
      "Result 4: {'title': 'Self-Supervised Learning and Its Applications - neptune.ai', 'link': 'https://neptune.ai/blog/self-supervised-learning', 'snippet': 'Self-supervised pre-trained models can generalize better to distribution shifts with MICLe pre-training leading to the most gains. This is a valuable finding, ...', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results highlight some of the challenges and limitations of self-supervised learning in AI. One of the most significant limitations is its computing demands. It also seems that while self-supervised learning can learn from unlabeled data, it may not be intrinsically better than human-based systems. These challenges and limitations suggest that while self-supervised learning is a promising approach towards achieving human or cat level intelligence in AI, there are still significant hurdles to overcome. \n",
      "\n",
      "Final Answer: Self-supervised learning is a significant step towards achieving human-level intelligence in AI, with advancements being made in this field. However, there are still many steps and challenges to overcome, including high computing demands and the need for further improvements in learning from unlabeled data. As for achieving cat level intelligence, there is no specific mention or measure, but it can be inferred that similar challenges would apply.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mSelf-supervised learning is a significant step towards achieving human-level intelligence in AI, with advancements being made in this field. However, there are still many steps and challenges to overcome, including high computing demands and the need for further improvements in learning from unlabeled data. As for achieving cat level intelligence, there is no specific mention or measure, but it can be inferred that similar challenges would apply.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered, it seems that while self-supervised learning is making strides towards human-level intelligence, there are still significant challenges to overcome. This includes high computing demands and the need for further improvements in learning from unlabeled data. The same challenges would likely apply to achieving cat level intelligence. However, there is no specific measure or percentage that quantifies the current progress of self-supervised learning towards achieving human or cat level intelligence. \n",
      "\n",
      "Final Answer: \"Self-supervised learning: Significant strides, yet challenges remain\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Self-supervised learning: Significant strides, yet challenges remain\"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_agent.run(generate_prompt(test_transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "- Search engine\n",
    "- Pushing agents to do realistic things\n",
    "- Ideas\n",
    "  - Generate realistic insights\n",
    "  - Multiple insights ideas\n",
    "  - Only ask to find for data easy to find\n",
    "  - Make the plan less rigid, who should I ask for help and ideas?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
